\section{\Acrlong{sispo}} \label{sec:sispo}

\gls{sispo} is a software package developed in python. It is separated in different sub-packages. The two main sub-packages are the \textit{sim} and the \textit{reconstruction} package. The third sub-package provides several image compression algorithms to test effects on reconstruction.

The software package is hosted on GitHub using a git version control system. Furthermore, the GitHub project management tools are used, including automated KanBan based projects, issue tracking and pull requests.

The most important python dependencies of \gls{sispo} are:
\begin{itemize}
    \item astropy: Astronomy package developed by \cite{robitaille2013astropy} and \cite{price2018astropy}
    \item Blender: 3D creation suite
    \item numpy: Scientific computing for python
    \item opencv: Computer vision library used for image processing
    \item OpenEXR: \gls{hdr} image reading and writing
    \item Orekit: Space dynamics library
\end{itemize}

It was attempted to reduce dependencies to other libraries as much as possible. Originally, both \textit{scikit-image} and \textit{opencv} were used. After a small benchmark between the two libraries, it was evident that \textit{opencv} performs three to seven times faster compared to \textit{scikit-image} (cf. \ref{sec:cvskimage}. Hence \textit{scikit-image} was completely replaced with equivalent \textit{opencv} functions. Additionally, it was attempted to use the \textit{opencv} package to replace the \textit{OpenEXR} dependency since it is not easy to install. However, this is currently not possible as the \textit{OpenEXR} implementation of \textit{opencv} does not provide an alpha channel and is generally less flexible.

To ease development, numerous parameters are silently assigned default values if not provided e.g. for an instrument. Therefore, all parameters should be explicitly set before running a simulation.

\gls{sispo} was developed in an attempt to logically separate the distinct steps involved of the entire processing pipeline. Such modularity eases further development as well as reduce unnecessary library imports to reduce memory consumption.

\subsection{User Interface}
The sispo package can be installed using pip and the GitHub project. If done, it will be installed into the site-packages folder of the used python environment. Additionally, an executable is installed, providing a \gls{cli} as user interface. The most recent possible input arguments are documented in the repository or by using the --help input. The most important arguments for the \gls{cli} are seen in Table \ref{tab:cli_args}.

\begin{table}[htpb]
\caption{Input arguments for sispo \gls{cli}}
\begin{tabular}{llll}
\hline
\textbf{Name}                            & \textbf{Variable Name} & \textbf{Default Value}     & \textbf{Description}                                                                                                      \\ \hline
\multicolumn{1}{l|}{--help}              &                        & ---                        & Prints list of arguments with hints                                                                                       \\
\multicolumn{1}{l|}{-i}                  & i                      & data/input/definition.json & Path to a definition file that defines the settings                                                                 \\
\multicolumn{1}{l|}{-v}                  & v                      & False                      & Verbose output, logging information will also be displayed on STDOUT                                                      \\
\multicolumn{1}{l|}{--cli}               & cli                    & False                      & If the \gls{cli} flag is set, an interactive \gls{cli} will be started. NOT IMPLEMENTED. \\
\multicolumn{1}{l|}{--profile}           & profile                & False                      & If the profile flag is set, Python's cProfile will be used to profile \gls{sispo} execution              \\
\multicolumn{1}{l|}{--no-sim}            & with\_sim              & True                       & If flag is set, simulation step will be skipped                                                                           \\
\multicolumn{1}{l|}{--no-render}         & with\_render           & True                       & If flag is set, rendering step will be skipped                                                                            \\
\multicolumn{1}{l|}{--no-compression}    & with\_compression      & True                       & If flag is set, compression step will be skipped                                                                          \\
\multicolumn{1}{l|}{--no-reconstruction} & with\_reconstruction   & True                       & If flag is set, reconstruction step will be skipped                                                                       \\
\multicolumn{1}{l|}{--sim-only}          & sim\_only              & False                      & If flag is set, only simulation step will be done                                                                         \\
\multicolumn{1}{l|}{--sim-render-only}   & sim\_render\_only      & False                      & If flag is set, only simulation and rendering will be done                                                                \\
\multicolumn{1}{l|}{--render-only}       & render\_only           & False                      & If flag is set, only rendering will be done                                                                               \\
\multicolumn{1}{l|}{--compress-only}     & compress\_only         & False                      & If flag is set, only compression will be done                                                                             \\
\multicolumn{1}{l|}{--reconstruct-only}  & reconstruct\_only      & False                      & If flag is set, only reconstruction will be done                                                                         

\end{tabular}
\label{tab:cli_args}
\end{table}

\gls{sispo} can be imported as a Python module. Execution is then started either by sispo.run() or sispo.main(), which are equivalent.

\subsection{Simulation Module}
The simulation module creates photo-realistic images by simulating a realistic trajectory of a \gls{sssb} and a spacecraft using Orekit. This trajectory and attitude data is then used to render four images per frame, one containing only the \gls{sssb}, one where the view is kept at a constant distance from the \gls{sssb}, one calibration reference image and one that renders a realistic star background using the \gls{ucac4}. Additionally, the date, the spacecraft position, \gls{sssb} position and their distance is stored as metadata. These images are composed to one image using photometry to calibrate the absolute light intensity of the different images in terms of realistic photon fluxes using the Johnson magnitude system \cite{bessel1979ubvri}. The composition process is explained in more detail in section \ref{sec:composition}

A run of the simulation package includes the following steps
\begin{enumerate}
    \item Propagate \label{enum:propagate}
    \item Render
\end{enumerate}

In the propagate step \ref{enum:propagate}, Orekit is used to determine state information of the \gls{sssb} and the spacecraft. The state information includes the date, position and the rotation angles of the \gls{sssb}. Propagation is defined by start and end date, number of steps, the timesampler mode and a slowmotion factor.
The timesampler mode determines whether the steps are distributed linear in time (mode 1, default) or whether an exponential model (mode 2) is used which takes more samples around the encounter. How many samples more are taken can be controlled with the slowmotion factor. Mode 2 is especially helpful when simulating a long period since far from the \gls{sssb} nucleus, there are only minor visible changes over longer periods.

The \textit{sim} sub-package was developed to contain all general information about the environment in the Environment class in order to have one consistent instance for constants. 

All images during the rendering and calibration process use the OpenEXR format to minimise the loss of information in intermediate steps.

The Orekit library runs a \gls{vm} to execute its Java code. Additionally, physical data is required which is currently distributed with the \textit{sim} sub-package. The \gls{vm} and physical data are initialised in the \textit{sim} main module and only afterwards other modules are imported which is why other modules do not include the Orekit initialisation. This approach was taken in order to reduce resource consumption by having several instances of the \gls{vm} running. Propagation is based on Orekit's KeplerianOrbit and KeplerianPropagator classes.

The initial state of the spacecraft is calculated based on the input parameters presented in \ref{tab:sc_enc_paras}. Only the three first parameters need to be given as input in the definition file.

\begin{table}[htb]
    \caption{Parameters that define the encounter state of the spacecraft.}
    \label{tab:sc_enc_paras}
    \begin{tabular}{p{0.23\textwidth}|p{0.06\textwidth}|p{0.62\textwidth}}
        Parameter           & Type  & Description                                                                                                                                                  \\ \hline
        encounter\_distance & float & Minimum distance between SSSB and spacecraft in meters                                                                                                       \\
        with\_terminator    & bool  & Determines whether the terminator is visible at the closest approach                                                                                         \\
        with\_sunnyside     & bool  & Determines whether the spacecraft passes the SSSB on the Sun facing side or the SSSB's side facing away from the Sun                                         \\
        sssb\_state         & tuple & \gls{sssb} state vector, including 3 position and 3 velocity components, at encounter. The spacecraft encounter state is calculated relative to this state vector. The \gls{sssb} state does not need to be set in the  definition file but is calculated based on the \gls{sssb} trajectory and encounter date.
    \end{tabular}
\end{table}

\subsubsection{Composition} \label{sec:composition}
Rendered images of blender vary in absolute light intensity thus requiring photometric calibration. This calibration is based on the Johnson magnitude system, also called the UBV photometric system \cite{bessel1979ubvri}. The V-band is used which is centered around \SI{550}{\nano\meter}.

The starting point for composition is a set of four images with the prefixes SssbOnly, SssbConstDist, LightRef and Stars. SssbOnly represents the view from the instrument. SssbConstDist is a follower camera at a constant distance of \SI{1000}{\kilo\meter} from the \gls{sssb}. LightRef is a defined reference model. Stars is an image of the star background. These images are then composed to a single final image.

The reference used for photometric calibration is the solar photon flux in the V-band at \SI{1}{\astronomicalunit} calculated based on \cite{wirth}.

The photon flux is defined as,
\begin{align}
    F = F_0 \times \frac{d\lambda}{\lambda} \times 10^{-0.4 \times m}, \label{eq:comp_flux_0mag}
\end{align}
with $F_0$ being the flux at magnitude 0, $\frac{d\lambda}{\lambda}$ is a factor of 0.16 for the V-band, and $m$ is the object's magnitude. The V-band photon flux at $0~mag$ in SI units is \SI{5.4964e10}{\per\second \per\square\meter}. With a magnitude of $m_{\bigodot} = -26.74~mag$ at a distance of \SI{1}{\astronomicalunit}, the solar photon flux becomes \SI{4.36715206e+20}{\per\second\per\square\meter}.

In the first step, the reference photon flux per pixel is calculated using,
\begin{align}
        F_{ref} = F \times \frac{\SI{1}{\astronomicalunit}}{d_{\bigodot}}^2 \times \frac{A \times pix_A}{f^2 \times \pi}, \label{eq:comp_ref_flux}
\end{align}
with $F$ being the solar flux at \SI{1}{\astronomicalunit}, $d_{\bigodot}$ being the spacecraft's distance from the Sun, $A$ being the aperture area, $pix_A$ being the area of a pixel and $f$ being the focal length.

For the star background, every pixel is calibrated according to Eq. \ref{eq:comp_cal_starmap}.
\begin{align}
        pix = pix_0 \times F_0 \times A \times \frac{F_{stars}}{S_{stars}}, \label{eq:comp_cal_starmap}
\end{align}
with $pix_0$ being the original pixel value, $F_0$ being the flux at magnitude 0, $A$ being the aperture area, $F_{stars}$ being the total flux of visible stars and $S_{stars}$ being the summed pixel value of one channel of a starmap.

Depending on the visible size of the \gls{sssb} in the image, either a point source \gls{sssb} image is generated and used or the \gls{sssb} image is calibrated.

The point source image is created by Gaussian filtering a single white pixel at the center of an image, oversized by a factor of five, and then downscaled to the original size using local means.

If the \gls{sssb} image is used, the reference intensity of the image is calculated as the mean of a \SI{70}{} square pixels of the light reference image.

Using the calibration factor defined as
\begin{align}
    f_c = \frac{F_{ref} \times I_{ref}}{\alpha}, \label{eq:comp_cal_fac}
\end{align}
where $F_{ref}$ is the reference flux, $I_{ref}$ is the reference intensity and $\alpha$ is the geometric albedo. Every pixel of the image is multiplied with this factor to produce the calibrated \gls{sssb} image. The star background and the calibrated \gls{sssb} image are merged taking the alpha values into account.

The composed image is then multiplied by the quantum efficiency of the \gls{ccd}, Gaussian filtered and noise based on a Poisson distribution is added. The resulting image is then scaled to an interval $[0,1]$ by dividing through the maximum value. In case a point source \gls{sssb} is used, the maximum value is clipped to five times the maximum of the the reference if the maximum value of the merged image is above this threshold.

In a final step, the image values are scaled to the bit depth of the \gls{ccd}. The current maximum allowed bit depth is \SI{16}{bit}. This feature can be turned off by setting the  \textit{with_clipping} parameter to false.

An additional feature is to add an infobox in the lower right corner of the image including the distance to the \gls{sssb} and the date. This feature can be turned off by setting the \textit{with_infobox} parameter to false.

\subsection{Compression Module}
The compression module provides compression and decompression algorithms. These can be tested against different mission scenarios and image series to investigate the impact of compression and decompression on the science quality.

The following set of compression algorithms 

\subsection{Reconstruction Module}
The reconstruction module can be used to generate a 3D model of an object using a series of images. It provides a full Multi-View Stereo reconstruction data process pipeline. To achieve this, two libraries are used and combined and called using python. The first library is \gls{omvg} by \cite{openMVG}. The second library is \gls{omvs}. 
The common steps for the complete pipeline is comprised of the following steps:
\begin{enumerate}
    \item Read in images [ImageListing in \gls{omvg}]
    \item Compute visual features [ComputeFeatures in \gls{omvg}]
    \item Match computed features between different images [MatchFeatures in \gls{omvg}]
    \item Generate point cloud from matched features [IncrementalSfM in \gls{omvg}]
    \item Export to \gls{omvs} format [openMVG2openMVS in \gls{omvg}]
    \item Increase number of points in point cloud [DensifyPointCloud in \gls{omvs}]
    \item Create a mesh from the point cloud [ReconstructMesh in \gls{omvs}]
    \item Refine the generated mesh [RefineMesh in \gls{omvs}]
    \item Apply texture to mesh to create final 3D model [TextureMesh in \gls{omvs}]
\end{enumerate}

\subsection{Setup}
\gls{sispo} can be setup with Linux and Windows. The default case used in this description is a Windows setup. Known differences or problems under Linux will be pointed out. While it should be possible to use a plain Python environment and pip, a miniconda environment manager was used for development. Also a C compiler is necessary. Linux provides the GCC, for Windows it is easiest to install Microsoft Visual Studio with \gls{msvc} and \gls{msbuild}. Another possibility when using Windows is to use vcpkg\footnote{Found at \url{https://github.com/microsoft/vcpkg}}. However, previously the openMVG and openMVS ports in vcpkg did not work. Vcpkg can also be used with Linux. However, there were unsolvable problems when using vcpkg so everything was installed natively.
For \gls{omvg}, \gls{omvs} and star\_cats it is necessary to have the executables in the correct folder for \gls{sispo} to function.\newline

\begin{figure}
    \dirtree{%
.1 sispo.
.2 build.
.2 data.
.3 UCAC4.
.4 u4b.
.4 u4i.
.3 sensor\_database.
.3 models.
.3 input.
.2 doc.
.2 sispo.
.3 sim.
.3 compression.
.3 reconstruction.
.2 software.
.3 miniconda.
.3 vcpkg.
.3 blender.
.3 openMVG.
.4 openMVG.
.4 build\_openMVG.
.5 install.
.3 openMVS.
.4 openMVS.
.4 build\_openMVS.
.5 install.
.3 star\_cats.
.4 star\_cats.
.4 build\_star\_cats.
}
    \caption{Directory structure after setup}
    \label{fig:dir_tree}
\end{figure}
Figure \ref{fig:dir_tree} shows the assumed overall folder structure after installation. No subfolders of the build folder or any files are depicted.

To make \gls{sispo} perform well, it is beneficial to install the Nvidia CUDA Toolkit (https://developer.nvidia.com/cuda-downloads) in case an Nvidia graphics card is available.

In the following enumeration, commands intended to be run in a shell are highlighted with a grey box.

\begin{enumerate}
    \item Clone the GitHub repository onto the local machine \\ \shellcmd{git clone https://github.com/YgabrielsY/sispo.git}. The project provides a software folder which is intended to be used to install all following software.
    \item Setup (conda) environment with dependencies (to software/miniconda folder):
    \begin{enumerate}
        \item orekit 9.3.1, the current version 10.0 have issues when once attempted. Also orekit needs a data package to function, it is distributed with \gls{sispo} in the sim module folder.
        \item astropy
        \item opencv
        \item OpenEXR\footnote{For Windows the pre-compiled package found at \url{https://www.lfd.uci.edu/~gohlke/pythonlibs/\#openexr} needs to be used because the pip or conda version do not work.}
        \item numpy
        \item Python\footnote{During development Python version 3.7 was used.}
    \end{enumerate}{}
    \item (Especially Windows) Install vcpkg to software/vcpkg folder, follow instructions at \url{https://github.com/microsoft/vcpkg}
    \item Install Blender as a python module (bpy)\footnote{During development Blender version 2.8 was used.}
    \begin{enumerate}
        \item Clone Blender git repository to software/blender/blender \\ \shellcmd{git clone git://git.blender.org/blender.git}
        \item Compile target bpy \shellcmd{make bpy}, this works also for Windows through the make.bat file provided with Blender
        \item When available: Activate CUDA in the cmake project and recompile
        \item Install bpy to python environment\footnote{Follow these instructions \url{https://blender.stackexchange.com/questions/117200/how-to-build-blender-as-a-python-module}}
    \end{enumerate}{}
    \item Install OpenMVG, follow instructions at \\ \url{https://github.com/openMVG/openMVG/blob/master/BUILD.md} or look for hints in the OpenMVG install script in the build folder.
    \begin{enumerate}
        \item Install dependencies according to instructions
        \item Clone OpenMVG GitHub repository to software/openMVG/openMVG \shellcmd{git clone --recursive https://github.com/openMVG/openMVG.git}
        \item Build to software/openMVG/build\_openMVG folder
        \item Install to software/openMVG/build\_openMVG/install folder
    \end{enumerate}
    \item Install OpenMVS, follow instructions at \\ \url{https://github.com/cdcseacave/openMVS/wiki/Building} or look at the OpenMVS install script in the build folder for hints.
    \begin{enumerate}
        \item Install dependencies according to instructions
        \item Clone OpenMVS GitHub repository to software/openMVS/openMVS \shellcmd{git clone https://github.com/cdcseacave/openMVS.git}
        \item Build to software/openMVS/build\_openMVS folder
        \item Install to software/openMVS/build\_openMVS/install folder
    \end{enumerate}
    \item Install star\_cats
    \begin{enumerate}
        \item Clone star\_cats GitHub repository to software/star\_cats/star\_cats \\ \shellcmd{git clone https://github.com/Bill-Gray/star\_cats.git}
        \item Build to software/star\_cats/build\_star\_cats \shellcmd{make}
    \end{enumerate}
    \item Download UCAC4 star catalog to data/UCAC4, use either:
    \begin{enumerate}
        \item the build/data/download\_ucac4.sh script
        \item download the folder u4b and u4i directly from \\ \url{http://casdc.china-vo.org/mirror/UCAC/UCAC4/}
    \end{enumerate}
\end{enumerate}{}

\subsection{Performance}
\subsubsection{Image processing benchmark} \label{sec:cvskimage}
The original codebase used the \gls{skimage} and OpenCV libraries. In order to reduce the number of dependencies, the relevant functions of the two libraries were benchmarked. For this comparison, OpenCV functions were used to create the same behaviour as the respective \gls{skimage} function. The benchmark compares the performance of the Gaussian filter and a special case of image resizing using local means. A set of five images is selected and are shown in Appendix \ref{sec:app_cvskimage}. Two star images were selected due to the large variance in the number of visible stars. The selected images represent extreme cases with 1804 (Stars1) and 51338 stars (Stars2).

Two computers are used for the benchmark. A laptop with \SI{8}{\giga\byte} \gls{ram}, an Intel i7-6700HQ with 4 cores at \SI{2.6}{\giga\hertz} and Windows 10. The second is a workstation computer with \SI{16}{\giga\byte} of \gls{ram}, an Intel i7-8700 with 6 cores at \SI{3.2}{\giga\hertz} and Ubuntu 18.04.3 LTS.

To compare the performance between the two libraries the ratio of execution time is used. The ratio is defined as
\begin{align}
    Ratio = \frac{t_{skimage}}{t_{opencv}}, \label{eq:bm_exec_ratio}
\end{align}
where $t_{skimage}$ is the execution time of \gls{skimage} and $t_{opencv}$ is the execution time of OpenCV. Each command is executed and timed for 1000 times. The lowest value is chosen as the result, since higher values are rather influenced by other processes running on the respective machine than the relevant code snippet itself \cite{timeit2020}.

Figure \ref{fig:bm_comparison} shows the execution time ratios with their averages over set of images. A ratio larger than one corresponds to a longer execution time of \gls{skimage}. OpenCV outperforms \gls{skimage} for both tests on both computers. The maximum absolute difference between pixel values of images is \SI{1.486e-6}{} and \SI{7.153e-7}{} for the Gaussian filtered and the resized images respectively. Such differences are irrelevant considering \gls{ccd} sensor color depths of \SI{16}{bit}.

%Maximum error gauss:  1.4864218655930017e-06
%Maximum error resize:  7.152557373046875e-07

\begin{figure}[htb]
    \centering
    \begin{subfigure}[b]{0.47\textwidth}
        \centering
        \includegraphics[width=\textwidth]{doc/thesis/0_figures/cv_skimage/Comparison_Gaussian}
        \caption{Gaussian filtering.}
        \label{fig:bm_comparison_gauss}
    \end{subfigure}
    \begin{subfigure}[b]{0.47\textwidth}
        \centering
        \includegraphics[width=\textwidth]{doc/thesis/0_figures/cv_skimage/Comparison_Resize}
        \caption{Resizing.}
        \label{fig:bm_comparison_res}
    \end{subfigure}
    \caption{Comparison of execution time ratios of Gaussian filtering and resizing five images using OpenCV and \gls{skimage} on two computers. Values $> 1$ correspond to OpenCV being faster. The mean values are given in the legend.}
    \label{fig:bm_comparison}
\end{figure}

For our case, OpenCV has a clear performance advantage over the \gls{skimage} library, hence only OpenCV is being used. In addition to the performance advantages, OpenCV might also be used to replace the OpenEXR dependency in the future, if OpenCV's OpenEXR implementation includes alpha channel support\footnote{A GitHub issue was created at \url{https://github.com/YgabrielsY/sispo/issues/128} that links to the relevant OpenCV GitHub issue.}.

\subsection{Future Developments}
There are several issues left open within the \gls{sispo} software package. First, there is currently no realistic model of spacecraft attitude motion and control implemented. The camera of the simulation environment is perfectly oriented towards the centre of the \gls{sssb}'s nucleus during the entire simulation. Realistic rotation should cover at least two effects, motion blur due to instantaneous rotation velocities of spacecraft and off-centre pointing due to control inaccuracies. Furthermore, it is necessary to include  image distortions such as astigmatism, bokeh, coma, field curvature, glare. Moreover, it is necessary to include a gas and dust environment around the nucleus. From a technical perspective, a proper simulation of the data transmission should be included. For example, a realistic simulation for packet loss. The ultimate goal is to develop a prioritisation algorithm for the images which should prioritise data transmission on packet level.
Moreover, multi-instumrent capability was intended as well as including multiple \gls{sssb}s in the future to allow more complex simulations including e.g. a binary system.
Furthermore, the shader used to create the \gls{sssb} models should be developed further. The interface for it should be included into \gls{sispo} and restricted to values that create reasonable shaped outputs.
An attempt to include a HAPKE model via the synthspace package \url{https://github.com/oknuutti/synthspace} was unsuccessful. However, it would be interesting to compare the results of blender and the HAPKE model. A HAPKE model is substantially faster while providing less detail though possibly still sufficient for some cases.

THOUGHTS:\\
-default data set, different compression and reconstruction\\
    -compressions: png, jpg2000 quality 1000, jpg2000 quality 500, jpg2000 quality 100, jpg2000 quality 10\\
-different trajectories: default : 400 km, 100km, 1000km\\
-different lighting situations\\
-different models 100m, 1km, 10km