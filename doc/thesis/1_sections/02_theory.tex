\section{Theory} \label{sec:theory}
% Physics part
% - Composition (photometry) -> telescope optics?/instrument?/bit depth?
% - Trajectories and relative trajectory of spacecraft, especially trajectories for flybys
% - Star rendering?
% - Describe physics of SSSBs, i.e. size/shapes/surface (features/color/albedo) illumination
%
% Computer Science part
% - Physics-based rendering? -Shaders/procedural terrain generation
% - Compression
% - Reconstruction (SfM), relates to camera physics. Generally Computer Vision topic.
% - Image processing Gaussian filtering, downscale local means
% - Logic for choosing number of reconstructed points as quality measure
%
% Space
% - Small Spacecrafts -> small data budgets?
%
% Max Science?
% Navigation/autonomy?
%
% Concepts to describe???

\subsection{Small Solar System Body}
The \gls{iau} defines a \gls{sssb} as any object in the Solar System, that is not a planet, dwarf planet or satellite \cite{iau_sssb}. Therefore, most asteroids, comets, Trans-Neptunian Objects, minor planets, meteorites and interplanetary dust are included in this definition \cite{wiki:sssb}. This is visualised in Figure \ref{fig:sssb_diagram}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{doc/thesis/0_figures/Euler_diagram_of_solar_system_bodies.png}
    \caption{The group of \glspl{sssb} (grey box) include a part of minor planets, trans-Neptunian objects, comets and centaurs \cite{wiki:sssb}.}
    \label{fig:sssb_diagram}
\end{figure}

Within this work, the term \gls{sssb} mostly refers to asteroids and comets. Therefore, general properties of asteroids and comets are explained in more detail.

\subsection{Asteroids}
Asteroids are rocky bodies that mostly reside in an orbit between Mars and Jupiter, i.e. the asteroid main belt. The terms asteroid and minor planet are often used interchangeably. Since most asteroids are only observed remotely, only their ephemeris and absolute magnitude is observed which gives a rough estimate of its size. However, some asteroids also have physical parameters like rotation period, geometric albedo, colours, spectral type, mass and bulk density.

\subsection{Comets}
Comets are small icy bodies and reside mostly in the outer Solar System. On long timescales, comets are perturbed by the gravity of other objects and leave their outer Solar System orbits to get closer to the Sun. In this process, the ices begin to evaporate. This creates the well known coma around the nucleus of a comet. In most cases the coma is several orders of magnitudes larger than the nucleus, the nucleus is on the order of a few kilometres while the coma can be on the order of hundreds of thousands of kilometres. Additionally, two tails are formed, a gas and a dust tail. The gas tail is formed from coma particles that move away from the nucleus and are then carried away by the solar wind. On the other hand, the dust tail is formed from dust particles in the coma which are carried away from the nucleus by the solar radiation pressure.

The physical parameters of comets are not well known, since they are too small for ground observations and it is difficult to image the nucleus when they come closer to the Sun since the nucleus is surrounded by the coma. While the ephemeris and magnitude are known for most comets, only a few comets have known rotation periods and geometric albedos.

\subsection{Computer Vision}
\Gls{cv} is the science of extracting information from digital photos and videos by mimicking the human vision system using a computer. \Gls{cv} encompasses a wide field of activities, from image formation, processing, detecting and matching features, image segmentation and three-dimensional reconstruction \cite{szeliski2010computer}. \Gls{cv} is the computer based variant of photogrammetry which is tasked with obtaining information about physical objects and the environment from photographic images \cite{linder2009digital}. The most common approach for three-dimensional reconstruction is stereo-photogrammetry, also referred to as computer stereo vision when using computers. Stereo-photogrammetry applies the binocular vision principle of the human vision system to obtain structural information from images \cite{do2019review}. Since most, if not all, deep space missions have a visual imager instrument on-board, \gls{cv} constitutes a logical approach of obtaining the three-dimensional structure of an observation target. A similar problem is the \gls{sfm} approach where the motion of the camera creates the different perspective.

\subsubsection{Structure-from-Motion}
\gls{sfm} uses multiple views of the same object from different camera positions to reconstruct the geometry of that object. \Gls{sfm} encompasses the recovery of the three-dimensional structure of an object as well as camera poses \cite{szeliski2010computer}. Depth information is obtained through the motion parallax created by the moving camera. Generic steps of a \gls{sfm} processing pipeline are shown in Figure \ref{fig:sfm_steps}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=.3\textwidth]{doc/thesis/0_figures/SfM.pdf}
    \caption{Generic steps of a \gls{sfm} processing pipeline.}
    \label{fig:sfm_steps}
\end{figure}

To reconstruct three-dimensional points from an image series, correspondence between images needs to be found. This is achieved by detecting features in an image that can be detected and matched in multiple images. A feature can be described as a local, meaningful and detectable part of an image. Features are being used because of their high information content. Features can be image regions of sudden change, shape features or texture contours. Commonly detected features are corners, edges, junctions, blobs and lines \cite{2018comparingfeatures}. These features are described using feature descriptors which assign a distinct identity to the described feature for later matching. A range of different feature detection algorithms  exist, sometimes with a ready to use algorithm. While most feature detectors are combined with a distinct feature descriptor, it is possible to interchange these. Feature detectors are tasked with detecting feature-points in an image. Feature points are also referred to as key-points or interest-points. A common requirement for good feature descriptors and detectors is that both should be scaling, rotation and affine invariant. The most commonly known feature detectors and descriptor pairs are \gls{sift}, \gls{surf}. \gls{orb}, KAZE and \gls{akaze} \cite{2018comparingfeatures}.
% Add SIFT description?
After features are detected and described in all images, these features need to be matched, i.e. an algorithm identifies the same feature in multiple images. Depending on the descriptor, either an L1 or L2 norm for a scalar descriptor or the hamming distance for binary descriptor are used. Feature matching can be carried out between image pairs or between a longer series of images. Different geometries can be described using different mappings. The homography matrix $\textbf{H}$ describes mapping of coordinates from two different views and is defined as
\begin{align}
    x'_i = \textbf{H}x_i, \label{eq:homography_m}
\end{align}
where $x'_i$ are the coordinates of point $i$ in the second image, $x_i$ are the coordinates of point $i$ in the first image and $\textbf{H}$ is the homography matrix. However, $\textbf{H}$ describes only a purely rotating or moving camera capturing a planar scene \cite{schonberger2016structure}.
The fundamental matrix $\textbf{F}$ describes the relation between two images of the same scene for a moving camera. It relates points of uncalibrated images and is defined as
\begin{align}
    {x'_i}^{T}\textbf{F}x_i = 0, \label{eq:fundamental_m}
\end{align}
where $x'_i$ are the coordinates of point $i$ in the second image, $x_i$ are the coordinates of point $i$ in the first image and $\textbf{F}$ is the fundamental matrix. The epipolar line
\begin{align}
    l'_i = \textbf{F}x_i, \label{eq:epipolar_l}
\end{align}
where $l'_i$ is the epipolar line, $\textbf{F}$ is the fundamental matrix and $x_i$ are the coordinates of a point in the first image. This line constitutes all possible positions of point $x'_i$.

If additionally, the camera intrinsics are taken into account, the fundamental matrix becomes the essential matrix $\textbf{E}$ which is defined as
\begin{align}
    \textbf{E} = \textbf{{K'}^T}\textbf{F}\textbf{K}, \label{eq:essential_m}
\end{align}
with $\textbf{E}$ being the essential matrix, \textbf{K'} being the camera matrix of the second view, \textbf{F} being the fundamental matrix as defined in Eq. \ref{eq:fundamental_m} and \textbf{K} being the camera matrix of the first view. Therefore, the essential matrix can only be used with calibrated images where the camera intrinsics are available.
If sufficient number of points are being mapped correctly using one of the transformation from Equations \ref{eq:homography_m}, \ref{eq:fundamental_m} or \ref{eq:essential_m}, the points are geometrically verified.

However after geometric verification, there might still be outliers. Therefore, outlier rejection is performed as an additional step to remove incorrect matches. Several algorithms such as \gls{ransac} \cite{fischler1981random}, \gls{acransac} \cite{moisan2012automatic}, \gls{msac} \cite{wang2009generalized} and \gls{prosac} \cite{chum2005matching} are used for outlier removal. The result of this step is the view graph that relates the different views to each other with images as nodes and pairs as edges \cite{schonberger2016structure}.

Using the view graph as an input, the reconstruction process produces a three-dimensional point cloud. There are two principle methods for reconstruction, incremental and global.

Incremental starts with an initial pair of views. Selecting this initial pair is a critical step as the reconstruction algorithm might not converge after using a bad initial pair. Typically, starting with a scene with many overlapping camera views constitutes a robust initialisation and results in higher accuracy because of the redundant information from many images \cite{schonberger2016structure}.



Features are also used to calibrate images and adjust camera intrinsics.
